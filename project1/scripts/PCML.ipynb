{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from proj1_helpers import *\n",
    "from costs import *\n",
    "from implementations import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_TRAIN_PATH = '../Data/train.csv' # TODO: add a file Data-Project1 with the train data \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete the outliers with the median\n",
    "def delete_outliers(tX):\n",
    "    for idx_feature in range(tX.shape[1]):\n",
    "        tX_feature = tX[:,idx_feature]\n",
    "        median = np.median(tX_feature[np.where(tX_feature != -999)])\n",
    "        new = np.where(tX_feature == -999, median, tX_feature)\n",
    "        tX[:, idx_feature] = np.copy(new)\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX = delete_outliers(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "stx, mean_stx, std_x = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y must be 0 or 1 and not -1 or 1\n",
    "def set_y(y):\n",
    "    y = np.where(y == -1, 0, y)\n",
    "    return y\n",
    "y = set_y(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the Features that do not provide any more information than the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAGeCAYAAACQHxmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XmcHXWd7//XWxBDEOOoQ4hXFlEwHRA0ccMNFBXFK+I2\n3iiCjjIu4+gvOldHx5Gg4yBucXTcBhX1h+bKXHdHRUUUYUS0gwKhIyjBUQmLgmFJgki+94+qhspJ\n9+kl3X2667yej8d5nD51vvWtT+2f861vVaeUgiRJktQmd+l1AJIkSdJUM8mVJElS65jkSpIkqXVM\nciVJktQ6JrmSJElqHZNcSZIktY5JriRJklrHJFeSJEmtY5IrSZKk1jHJ1bRLsjXJ0T2Y7vokr+nB\ndA+r5/keMz3tjjj2qeM4uJdxTLUkxye5YYLjbLMs6nV0+3Sso+b2Pt3roFf71ghxLEzynSQ3J7m+\n1/FIEpjkagcluU+SjyT5dZItSTYk+WaSQxvF9gS+2asYe6Tr/8tOcmWdoGxN8uckv0vy8ST3nMk4\n5rDJzFdznPOARaWUG8caaRI/Wjq39x1eB0lOTHLhOKbVKyuAhcDBwAEjFajnYWv942Jr4+8nTlUQ\nXZbTjEnyrCQ/SXJDnfRfmOTYXsYk9audex2A5rwvUm1HLwLWU53ojgDuPVyglHJtb0Kb1QrwFuDj\nwE5UicGpwL8Cx0/hdDKFdVUVJjuXUv481fXOgDuWRR3/eLfLUK2vrssyyV1LKbeNsL1P1TrYLlme\nRfvWA4DBUsoVY5S7hOr40FwmU93yOyU/7JLsVEq5fRKj/gH4Z2Ad8CfgGcBpSa4ppXxnKmKTND62\n5GrSkiwAHgu8sZRyTinlN6WUn5ZSTimlfL1RbptLqkkeXbdubE5yfpJnjHApeWuSJ9YtIrckOS/J\nAY069kvy5SRXJ7kpyQVJjphg/A9L8u0k1yX5Y5LvJ3loR5mtSV6a5It1HJcleUZHmaOS/CLJpiRn\nAfuOM4SbSynXllI2lFJ+AHwaWNqo915JPpfkt/W0L0ryvzqmnSRvSHJ53ZJ+ZZI3jTK/d0nyySSX\nJrlfPexBSc6t18XFSQ4f5XL7X9XLZxPwgvq75yS5pJ7u+iSvG2HZHd0x7IYkx3XU/awk36vn8WdJ\nHtUxzovrKwU3J/kCjR9Qo0nyiCRr6vm6AHgojeSns3U2yd5Jvprk+no6Fyd5apJ9gO/Vo91Qtzx+\nsh7n7CQfTLIqyXXAt0abb2Cg3oaHl/PjG7Fs1/0iyTFJtg5/D5wIHJI7Wz+Hl2HnvnVQkrPqbfH3\nST6WZLfG96cl+VKS1ye5qi7zb0l2GmN5vjLJL5PcmmQojZbJJOuBZwPHN5fPKP5cSrmu3u6HX3f8\nYErysnr73Fy/v7IjjnfW+9otSX6V5G3DsY+2nDJCl5EkC+phj68/D28PT03y0yRbgMfU3z0zyWAd\n0y+TvDXJqOfO+lj4lVLKL0op60spHwAuojpWSppJpRRfvib1omqBvBF4L7BLl3JbgaPrv3cHfg98\nClgMHAkMAbcDB9dlDqvH+S+qE8Ni4AfADxt1HgycAAxQtSKdBNwC3K9RZj3wmi5xPYEqYdsfeBDw\n78AGYLeO2H8N/BWwH/D+ep7vWX9/P2Az8K66nuV1HbcD9+gy7W1iA/4HcD5wamPYfYHXAQ+mSpz/\nlqpl6GGNMqfUy/NY4P7AI4GX1N/tU8d/MLALVav7T4F71d/fhaq16ZvAQcCj6xhub6yv4Tp+BRxT\nf14ILAP+DLwZeCBwXL38jxtpvTeG3TBcplH3WuCpdT1nAFcAd6nLPLKezuvr719N1fJ3fZdluxtw\nDfCZevs4Cvgl229jd6wj4OtUSeqSelkfRbXtBXhWXfYBwB7A7vU4ZwMbgXfW637/Ebb34Xn8db38\nhrezjcBf1GWO75wf4JnA7fXf84B3UyVKf1nHcLcRpjUf+F29DAeAw+v19slGvacBfwQ+RHX14Cjg\nZuClXZbns4BbgZfX62AFcBtwWP39vYFvAKvr+HYfpZ4TgTVdpvNC4Lf1vO9TL6/rgBc1yry53ib2\nBp4OXAX8fbflVNd1x7qvyy6ol93jO445F1K1NN8fuCfwuHp5HVvXc0S9TP9pAsfJI4CbgCf26ljt\ny1e/vnoegK+5/apPgL8HNgHnAu8AHtxRpnkifgXVZeJdGt+/lJETkMMbZZ5WD+uWTF8MvKrxuWuS\nO8L4d6FKPo7qiH1l4/P8ethT6s//AlzcUc/JjC/J3Vyf/DZxZ1I/6jj1eF8D3lX/ffe6jpeMUnb4\n5P4Y4DvA95sJCFVieSvwl41hRzBykvbqjrpPB77VMeyU5rJg/EnuixvfD9QxH1B//izwtY46VtM9\nyf2bEbaxl4+yjQ0nuT9nlMSls2xj+NnAT0coP9Ly+/vG9zsB/82dyVnXJLf+PGKC2DGtE6j2xXkd\n+82fh9cxVZJ7BZBGmc8Dn+uyPM8FPtIx7PPN9QJ8iUYyPUo9J9ax3Ei13d8EnN/4/nLg+R3j/CNw\nXpc6Xw9c0G05NdbBeJLc/9kx7neorlQ1h70Q+N0Y83qPev7+RLV/v7hbeV++fE3Py+4K2iGllC9R\ntTg+g6pF8DBgzfDl1BEcAFxUSvlTY9gFo5S9uPH3hvp9D4AkuyV5T31J84YkN1G1+O493tiT7JHk\n1FRdEP5IleDuNkIdd8RRStlEdZLeox60GPhxR/kfjTOEdwOHULXUPpGq1fAbSVLHd5ck/5Sqm8If\n6nl8SiO+AaoW2u9tX/Wds0mVFM4Hjiyl3NT47gDgN6WU6xrDRlsXgx2fB6hu3mo6D9h/OP4J6FzP\n4c7lO8DEl+9itt/GxhrnA8A/peq6sTLJg8coP6xzuYzm/OE/StXP86dU8zaVFgM/L6VsaQw7j+rH\n24Maw9aWUkrj8wbuXN4jGaD6AdZ0HpOLfx3VNj/8eg5AkvlULeWfSNX96KZ6e/9HqlZV6nLPr9fR\nhvr7f2YC+/wYCtuvz0OAt3bEdCqwMMm8LnXdVI/7sHoeVjW7qEiaGd54ph1WJxNn1a93JDmVqvvA\nZ3aw6tuak6nfh3+YvZeq1fH1VJcPNwNfoEr6xuszwF8Af0fVsnYrVTLSWcdtHZ8LU9Of/fflzht1\nfpXktfX0n0CVuL6hju21VDfs3EJ1Y9pwfJvHOZ3/pLrc+miq1sfJuGUS4xS2v+nqriOU67aeZ0Qp\n5RNJvkV1CfwpwJuSvK6U8qExRp3Mcum0lfEtp6kyXdvzePyplLJ+hOF3r99fxvY/tG4HSPXEltOB\nfwK+TfWjdDlVl55uttbvzWU82vLtXJ93B95K1dVnGx0/Jjq/K1Qt5gAXJVkCvAk4Z4xYJU0hW3I1\nHYaoWkRH8gvgwUmaJ5lHTGIajwY+VUr5aillLdXl6X0nUccHSilnllKGqE7+95lgHUNsH/+hIxUc\nh+EEb9dGfF8ppawupVxM1cWh+Ximy4EtVMl+tzo/QnWC/WpHa9IvgL2S/GVj2EjroowwbIj6xpyG\nxwKXNVoJrwMWDX+ZZH+qFuWx6u6cziM7ho21fIeAg5M0f6yMuU5KKb8rpfx7KeW5VD+iTqi/Gm4R\n7npz1hjuuJmuvlFqGXBpPeg6YPckuzbKb3MDZB3DWNMforrpqlnPY6mSxF9MJuhGvZ3r+jHcGf8O\nK9VTIq4CHlBKuaLj9eu62KHAlaWUd5ZS1pRSfsX2+/xIy2n4SsWixrBtbkTsYg3woBFiGuspEp3u\nQtU/WNIMsiVXk5bkXsB/AJ+kutnjJuDhwP8GvjzKaJ+j6rd7apJ3UvWXe339XfOkM9Il7+awy4Fn\nJxl+isPbRhmnm8uBFyUZpOqj9y6q/nMT8VHgdUneRfU4sIcx/keA7Z5kIVXce1P1ab2WOy8NXw48\np27B+iN3Pot0LUAp5dYkpwDvSnIb1SXkvwQOLKUM3+GeuuzwHfRfS3JUKeU8qv6GVwCfSfIGqn6E\n/0y1HsZaF+8FLkjyFqr+mY+mujHuFY0y3wNeneR8qmPNO7kzYexWd9MHgHOTvB74ClU/4iPHGOdz\n9Xx8PMnJVJe7Xz9CuTumnWQVVXeby4B7UbWmDydxv6ZaHs9I8g1gcylloi24f5vkl1QJ4+uobmo6\nrf7ux1Tb3clJPkCVEHduQ1cC909yCNXNWTd1dMeAqv/ySuDTSU6i6oLwAeAzHV1SJurdwOeT/Az4\nLnA0VV/8CT3NZBxOBP41yY1UNwHejWp/umcp5f1U+8PeSZ4P/AT4n1Q3pzVdyfbLaUu9Df5Dkiup\n9qG3jzD9kbbFt1HtM78B/i9Vq/AhwEGllH8aaSaS/ANVd5Rf1fPwdKorKa8YqbykadTrTsG+5u6L\n6rL5O6hOONdTJbmXUp1o79Yod8fd+vXnR1HdxbyZ6tLk8+syw3enb3ejD9WJ5XZg7/rzPlQn3Jup\nTmyvpEqq3tcY5wq6P13hEKoE4xaqvoLP7hynM/Z62PVs+xSBo6hayjZR3dx1fGf8I0x7fV1m+HU1\n1U1lzZtj/oLqMulGqn6TJ1ElRl/sqOtNddxb6nrf2FhGnXeVr6BKmB9Vfz6A6hLqZqrk+elUJ/In\nj1ZHo65nUfWnHZ7uio7vF1EljjfWy/fI5rIbJb4F9bDHN4a9mCrRvJnqx9MKutx4Vo/zCKpWuM1U\n/SyPofuNZx+gSnA31eviNOqnH9Tf/yNVS+OfqW+wour68b4Rpt35dIrbqbbx8+t4Lm7OX13u6Hob\nupkqmX8p2954tgvVUxOur+s7rnNa9ecDqfaLW6haMD8CzG98P9L2swr43hjL8+XceeVgCHhBx/fj\nvfFs1Kcr1GX+V2O9/b5exs9sfP9Oqh+CG6l+zLymuS10WU6LqW6gu7neHo5obmed20NHTE8GfliP\newNV/+5uT6N4e70ub6nn4Vzgud3m25cvX9PzSinjuWIjTZ8kLwQ+ASwopdza63j6WZLHUCW9Dywj\n952UJGlOsLuCZlySF1G1PP4OeAhV68znTXBnXpJjqFqoLqd61uv7gXNNcCVJc51JrnphT6q+bgup\nLsN/nupf3Grm7U7VF3gvqkur3wH+vqcRSZI0BeyuIEmSpNbxEWKSJElqHZNcSZIktY5JriRJklrH\nJFeSJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia5kiRJah2TXEmSJLWOSa4kSZJap2+S\n3CRvSnJBkhuTXJPkS0kOGMd4hycZTLIlyWVJjp+JeCVJkjR5fZPkAo8DPgg8EngScFfg20l2HW2E\nJPsCXwfOAg4B/hX4eJInT3ewkiRJmryUUnodQ08kuQ9wLfD4Usq5o5Q5BXhaKeXgxrDVwIJSylEz\nE6kkSZImqp9acjvdEyjA9V3KPAr4bsewM4FDpysoSZIk7bidex1ALyQJ8H7g3FLKpV2K7glc0zHs\nGuAeSe5WSrl1hLrvDRwJXAlsmZqIJUnqC/OAfYEzSyl/6HEsmuP6MskFPgwsAR4zDXUfCXx2GuqV\nJKlfvBD4XK+D0NzWd0lukn8DjgIeV0rZMEbxq4GFHcMWAjeO1IpbuxLg9NNPZ2BgYEdC1SyxYsUK\nVq1a1eswJI3CfbQ9hoaGOPbYY6E+l0o7oq+S3DrBfSZwWCnlv8cxyo+Ap3UMe0o9fDRbAAYGBli6\ndOmk4tTssmDBAtelNIu5j7aS3f20w/rmxrMkH6a6/PEC4JYkC+vXvEaZf0ny6cZoHwX2S3JKkgcl\neRXwXOB9Mxq8JEmSJqRvklzgFcA9gO8DVzVef9UoswjYa/hDKeVK4OlUz9X9GbACeGkppfOJC5Ik\nSZpF+qa7QillzIS+lPKSEYadAyyblqAkSZI0LfqpJVealOXLl/c6BElduI9KGolJrjQGT6DS7OY+\nKmkkJrmSJElqHZNcSZIktY5JriRJklrHJFeSJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLU\nOia5kiRJah2TXEmSJLWOSa4kSZJaxyRXkiRJrWOSK0mSpNYxyZUkSVLrmORKkiSpdUxyJUmS1Dom\nuZIkSWodk1xJkiS1zs69DkCSpJFs2rSJdevWTUldixcvZv78+VNSl6S5wSRXkjQrrVu3jmXLlk1J\nXYODgyxdunRK6pI0N5jkSpJmpcWLFzM4ONi1zNAQHHssnH46DAx0r0tSfzHJlSTNSvPnzx936+vA\nANhQK6nJG88kSZLUOia5kiRJah2TXEmSJLWOSa4kac5atAhOPLF6l6SmvkpykzwuyVeT/C7J1iRH\nj1H+sLpc83V7kj1mKmZJ0ugWLYKVK01yJW2vr5JcYDfgZ8CrgDLOcQqwP7Bn/VpUSrl2esKTJEnS\nVOirR4iVUr4FfAsgSSYw6nWllBunJypJkiRNtX5ryZ2MAD9LclWSbyd5dK8DkiRJUncmud1tAF4O\nPAd4NvAb4PtJHtLTqCRJktRVX3VXmKhSymXAZY1B5yd5ALACOL7buCtWrGDBggXbDFu+fDnLly+f\n8jglSZprVq9ezerVq7cZtnHjxh5FozZKKeO9/6pdkmwFjimlfHWC470LeEwp5TGjfL8UGBwcHBz3\nv6OUJEmwZs0ali1bBrCslLKm1/FobrO7wsQ9hKobgySpxzZvhrVrq3dJauqr7gpJdgMeSHUzGcB+\nSQ4Bri+l/CbJycB9SynH1+VfC6wH1gLzgBOAJwBPnvHgJUnbGRqCZctgcBC8eCapqa+SXOBhwNlU\nz74twHvr4Z8G/prqObh7NcrvUpe5L7AJuAg4opRyzkwFLEmSpInrqyS3lPIDunTRKKW8pOPzu4F3\nT3dckiRJmlr2yZUkSVLrmORKkiSpdUxyJUmS1DomuZIkSWodk1xJkiS1Tl89XUGS1C4DA3DJJbDf\nfr2ORNJsY5IrSZqzdt0VDjyw11FImo3sriBJkqTWMcmVJElS65jkSpIkqXVMciVJktQ6JrmSJElq\nHZNcSZIktY5JriRpztqwAVaurN4lqckkV5I0Z23YACedZJIraXsmuZIkSWodk1xJkiS1jkmuJEmS\nWsckV5IkSa2zc68DkHpp06ZNrFu3bkrqWrx4MfPnz5+SuiRJ0o4xyVVfW7duHcuWLZuSugYHB1m6\ndOmU1CVJknaMSa762uLFixkcHBz1+6EhOPZYOP10GBgYuy5JM2vePFiypHqXpCaTXPW1+fPnj6v1\ndWAAbKSVZp8lS2Dt2l5HIWk28sYzqQtbiSRJmptsyZW6sJVIkqS5yZZcSZIktY5JriRJklqnr5Lc\nJI9L8tUkv0uyNcnR4xjn8CSDSbYkuSzJ8TMRqyRJkiavr5JcYDfgZ8CrgDJW4ST7Al8HzgIOAf4V\n+HiSJ09fiJIkSdpRfXXjWSnlW8C3AJJkHKO8EriilPKG+vMvkjwWWAF8Z3qilCRJ0o7qt5bciXoU\n8N2OYWcCh/YgFklSh0svhQMPrN4lqckkt7s9gWs6hl0D3CPJ3XoQjySpYcuWKsHdsqXXkUiabUxy\npS5sJZIkaW7qqz65k3A1sLBj2ELgxlLKrd1GXLFiBQsWLNhm2PLly1m+fPnURqhpZSuRJE2P1atX\ns3r16m2Gbdy4sUfRqI1Mcrv7EfC0jmFPqYd3tWrVKpYuXTotQUmSNNeN1PCzZs0ali1b1qOI1DZ9\n1V0hyW5JDknykHrQfvXnvervT07y6cYoH63LnJLkQUleBTwXeN8Mhy5JkqQJ6KskF3gYcCEwSPWc\n3PcCa4CT6u/3BPYaLlxKuRJ4OvAkqufrrgBeWkrpfOKCJEmSZpG+6q5QSvkBXRL7UspLRhh2DuC1\nE0mSpDmk31pyJUktsmgRnHhi9S5JTX3VkitJapdFi2Dlyl5HIWk2siVX6sJWIkmS5iZbcqUubCWS\nJGlusiVXkiRJrWOSK0mSpNYxyZUkSVLrmORKkiSpdUxyJUlz1ubNsHZt9S5JTSa5kqQ5a2gIDjqo\nepekJpNcqQtbiSRJmptMcqUubCWSJGluMsmVJElS65jkSpIkqXVMciVJktQ6JrmSJElqHZNcSZIk\ntc7OvQ5AkqTJGhiASy6B/fbrdSSSZhuTXEnSnLXrrnDggb2OQtJsZJIrdWErkSRJc5NJrtSFrUSS\nJM1N3ngmSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia5kqQ5a8MGWLmyepekJpNcSdKctWEDnHSS\nSa6k7ZnkSl3YSiRJ0tzUd0lukr9Nsj7J5iTnJ3l4l7KHJdna8bo9yR4zGbN6x1YiSZLmpr5KcpM8\nH3gvcCLwUODnwJlJ7tNltALsD+xZvxaVUq6d7lglSZI0eX2V5AIrgI+VUj5TSlkHvALYBPz1GONd\nV0q5dvg17VFKkiRph/RNkpvkrsAy4KzhYaWUAnwXOLTbqMDPklyV5NtJHj29kUqSJGlH9U2SC9wH\n2Am4pmP4NVTdEEayAXg58Bzg2cBvgO8nech0BSlJkqQdt3OvA5jNSimXAZc1Bp2f5AFU3R6O7zbu\nihUrWLBgwTbDli9fzvLly6c8TknqV/PmwZIl1bvmltWrV7N69epthm3cuLFH0aiN+inJ/T1wO7Cw\nY/hC4OoJ1HMB8JixCq1atYqlS5dOoFpJ0kQtWQJr1/Y6Ck3GSA0/a9asYdmyZT2KSG3TN90VSim3\nAYPAEcPDkqT+/F8TqOohVN0Y1AdsJZIkaW7qp5ZcgPcBn0oySNUiuwKYD3wKIMnJwH1LKcfXn18L\nrAfWAvOAE4AnAE+e8cjVE7YSSZI0N/VVkltKOaN+Ju7bqLop/Aw4spRyXV1kT2Cvxii7UD1X975U\njxq7CDiilHLOzEUtSZKkieqrJBeglPJh4MOjfPeSjs/vBt49E3FJkiRp6vRNn1xJkiT1D5NcSZIk\ntY5JriRJklrHJFeSNGddeikceGD1LklNJrmSpDlry5Yqwd2ypdeRSJptTHKlLmwlkiRpbjLJlbqw\nlUiSpLnJJFeSJEmtY5IrSZKk1jHJlSRJUuv03b/1lSTNDpdfDjfdtGN1DA1t+z5Zu+8O+++/Y3VI\nml1MciVJM+7yy+GAA6auvmOP3fE6LrvMRFdqE5NctdqOthRNVSsR2FIkNQ3vl6efDgMDvY1laKhK\nkne0VVnS7GKSq9aaypaiqWglAluKpE4DA7B0aa+jkNRGJrlqLVuKJEnqXya5aj1biiRJ6j8+QkyS\nJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia5kiRJah2TXEmSJLWOSa4kSZJaxyRXkiRJ\nrWOSK0mSpNYxyZUkSVLrmORKkiSpdfouyU3yt0nWJ9mc5PwkDx+j/OFJBpNsSXJZkuNnKlZJkiRN\nTl8luUmeD7wXOBF4KPBz4Mwk9xml/L7A14GzgEOAfwU+nuTJMxGvJEmSJqevklxgBfCxUspnSinr\ngFcAm4C/HqX8K4ErSilvKKX8opTyIeD/1vVIkiRpluqbJDfJXYFlVK2yAJRSCvBd4NBRRntU/X3T\nmV3KS5IkaRbomyQXuA+wE3BNx/BrgD1HGWfPUcrfI8ndpjY8SZIkTZWdex1AW61YsYIFCxZsM2z5\n8uUsX768RxFJkjR7rF69mtWrV28zbOPGjT2KRm3UT0nu74HbgYUdwxcCV48yztWjlL+xlHJrt4mt\nWrWKpUuXTiZOSZJab6SGnzVr1rBs2bIeRaS26Zskt5RyW5JB4AjgqwBJUn/+wCij/Qh4Wsewp9TD\nNctl8yYeyjp2Hep1JLDrUPU4j2xeDMzvdTiSJLVe3yS5tfcBn6qT3QuonpIwH/gUQJKTgfuWUoaf\nhftR4G+TnAJ8kiohfi5w1AzHrUmYd+U61rAMju11JDAArAGGrhyEx9jCL0nSdOurJLeUckb9TNy3\nUXU7+BlwZCnlurrInsBejfJXJnk6sAp4DfBb4KWllM4nLmgW2rLvYpYyyGdPh4GB3sYyNAQvPBY+\nse/i3gYiSVKf6KskF6CU8mHgw6N895IRhp1D9egxzTFl1/lcyFI2DwA9bjzdDFwIlF17G4ckSf2i\nnx4hJkmSpD5hkitJkqTWMcmVJElS65jkSpIkqXVMciVJktQ6JrmSJElqHZNcSZIktY5JriRJklrH\nJFeSJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia5kiRJah2TXEmSJLXOzr0OQJLUf7J5\nEw9lHbsO9ToS2HUIHgpk82Jgfq/DkTRFTHIlSTNu3pXrWMMyOLbXkcAAsAYYunIQHrO01+FImiIm\nuZKkGbdl38UsZZDPng4DA72NZWgIXngsfGLfxb0NRNKUMsmVJM24sut8LmQpmweAHjeebgYuBMqu\nvY1D0tQyyVVrbdpUva9Z09s4oGopkiRJM8ckV621bl31fsIJvY2jaffdex2BJEn9wSRXrXXMMdX7\n4sUwf5I3TA8NwbHHwulT0G9w991h//13rA5JkjQ+JrlqrfvcB172sqmpa2AAlnrTtSRJc4b/DEKS\nJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOn2T5Cb5iySfTbIxyQ1JPp5ktzHGOS3J1o7X\nN2YqZvXevHmwZEn1LkmS5o5+eoTY54CFwBHALsCngI8Bx44x3jeBFwOpP986PeFpNlqyBNau7XUU\nkiRpovoiyU2yGDgSWFZKubAe9nfAfyb5+1LK1V1Gv7WUct1MxClJkqSp0S/dFQ4FbhhOcGvfBQrw\nyDHGPTzJNUnWJflwkntNW5SSJEmaEn3RkgvsCVzbHFBKuT3J9fV3o/km8AVgPfAA4GTgG0kOLaWU\n6QpWkiRJO2ZOJ7lJTgbe2KVIAQYmW38p5YzGx7VJLgZ+BRwOnN1t3BUrVrBgwYJthi1fvpzly5dP\nNhxJklpj9erVrF69epthGzdu7FE0aqM5neQC7wFOG6PMFcDVwB7NgUl2Au5VfzcupZT1SX4PPJAx\nktxVq1axdOnS8VYtSVJfGanhZ82aNSxbtqxHEalt5nSSW0r5A/CHscol+RFwzyQPbfTLPYLqiQk/\nHu/0ktwPuDewYRLhSpIkaYb0xY1npZR1wJnAqUkenuQxwAeB1c0nK9Q3lz2z/nu3JO9K8sgk+yQ5\nAvgycFl+pXiUAAAgAElEQVRdlyRJkmapvkhyay8A1lE9VeHrwDnAyzvK7A8Md6S9HTgY+ArwC+BU\n4CfA40spt81EwOq9Sy+FAw+s3iVJ0twxp7srTEQp5Y+M8Y8fSik7Nf7eAjx1uuPS7LZlS5XgbtnS\n60gkSdJE9FNLriRJkvqESa4kSZJaxyRXkiRJrdM3fXIlSbPHpk3V+5o1vY0DYGio1xFImg4muZKk\nGbduXfV+wgm9jaNp9917HYGkqWSSK0maccccU70vXgzz50++nqEhOPZYOP10GJj0P3GvEtz995/8\n+JJmH5NcqYtFi+DEE6t3SVPnPveBl71s6uobGAD/k7qkJpNcqYtFi2Dlyl5HIUmSJsqnK0iSJKl1\nTHIlSZLUOia5kiRJah2TXEmSJLWOSa4kac6aNw+WLKneJanJpytIkuasJUtg7dpeRyFpNrIlV+pi\n8+bqBLp5c68jkSRJE2GSK3UxNAQHHeT/tpckaa4xyZUkSVLrmORKkiSpdUxyJUmS1DomuZIkSWod\nk1xJkiS1jkmuJGnOuvRSOPDA6l2SmkxyJUlz1pYtVYK7ZUuvI5E02/gfz6QuBgbgkktgv/16HYkk\nSZoIk1ypi113rS6FSpKkucXuCpIkSWodk1xJkiS1Tt8kuUnenOS8JLckuX4C470tyVVJNiX5TpIH\nTmeckiRJ2nF9k+QCdwXOAD4y3hGSvBF4NfA3wCOAW4Azk+wyLRFKkiRpSvTNjWellJMAkhw/gdFe\nC7y9lPL1etzjgGuAY6gSZklSDy1aBCeeWL1LUlM/teROSJL7A3sCZw0PK6XcCPwYOLRXcUmS7rRo\nEaxcaZIraXsmuaPbEyhULbdN19TfqQ9s2FCdQDds6HUkkiRpIuZ0kpvk5CRbu7xuT3JAr+PU3LVh\nA5x0kkmuJElzzVzvk/se4LQxylwxybqvBgIsZNvW3IXAhWONvGLFChYsWLDNsOXLl7N8+fJJhiNJ\nUnusXr2a1atXbzNs48aNPYpGbTSnk9xSyh+AP0xT3euTXA0cAVwEkOQewCOBD401/qpVq1i6dOl0\nhCZJ0pw3UsPPmjVrWLZsWY8iUtvM6e4KE5FkrySHAPsAOyU5pH7t1iizLskzG6O9H3hLkmckeTDw\nGeC3wFdmNHhJkiRNyJxuyZ2gtwHHNT6vqd+fAJxT/70/cEcfg1LKu5LMBz4G3BP4IfC0Usqfpj9c\nSZIkTVbfJLmllJcALxmjzE4jDFsJrJyeqCRJO2LzZrjiCthvP9h1115HI2k26ZvuCpKk9hkagoMO\nqt4lqckkV+pi3jxYsqR6lyRJc0ffdFeQJmPJEli7ttdRSJKkibIlV5IkSa1jkitJkqTWMcmVJElS\n65jkSpIkqXVMciVJktQ6Pl1BkjRnDQzAJZdU/wxCkppMciVJc9auu8KBB/Y6Ckmzkd0VpC4uvbQ6\ngV56aa8jkSRJE2GSK3WxZUuV4G7Z0utIJEnSRNhdQX1t06ZNrFu3btTvh4a2fe9m8eLFzJ8/f4oi\nkyRJO8IkV31t3bp1LFu2bMxyxx47dl2Dg4MsXbp0CqKSJEk7yiRXfW3x4sUMDg5OWV2SJGl2MMlV\nX5s/f76tr5IktZA3nkmS5qwNG2DlyupdkppMciVJc9aGDXDSSSa5krZnkitJkqTWMcmVJElS65jk\nSpIkqXVMciVJktQ6JrmSJElqHZNcSZIktY5JriRpzpo3D5Ysqd4lqcn/eCZJmrOWLIG1a3sdhaTZ\nyJZcSZIktY5JriRJklqnb5LcJG9Ocl6SW5JcP85xTkuyteP1jemOVZIkSTumn/rk3hU4A/gR8NcT\nGO+bwIuB1J9vndqwJEmSNNX6JsktpZwEkOT4CY56aynlumkISZIkSdOkb7or7IDDk1yTZF2SDye5\nV68DkiRJUnd905I7Sd8EvgCsBx4AnAx8I8mhpZTS08gkSZI0qjmd5CY5GXhjlyIFGCilXDaZ+ksp\nZzQ+rk1yMfAr4HDg7G7jrlixggULFmwzbPny5SxfvnwyoUiSRnDppfC858F//Ef1zFzNHatXr2b1\n6tXbDNu4cWOPolEbZS43SCa5N3DvMYpdUUr5c2Oc44FVpZRJdTtIci3wj6WUU0f5fikwODg4yNKl\nSyczCUnSOK1ZA8uWweAgeMid+9asWcOyZcsAlpVS1vQ6Hs1tc7olt5TyB+APMzW9JPejSqo3zNQ0\nJUmSNHF9c+NZkr2SHALsA+yU5JD6tVujzLokz6z/3i3Ju5I8Msk+SY4AvgxcBpzZk5mQJEnSuMzp\nltwJehtwXOPz8GWQJwDn1H/vDwx3pL0dOLge557AVVTJ7VtLKbdNe7SSJEmatL5JckspLwFeMkaZ\nnRp/bwGeOt1xSZIkaer1TXcFSZIk9Q+TXEmSJLWOSa4kac5atAhOPLF6l6SmvumTK0lqn0WLYOXK\nXkchaTayJVeSJEmtY5IrSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia5kiRJah2TXEnSnLV5M6xd\nW71LUpNJriRpzhoagoMOqt4lqckkV5IkSa1jkitJkqTWMcmVJElS65jkSpIkqXVMciVJktQ6JrmS\nJElqHZNcSZIktc7OvQ5AkqSRbNq0iXXr1nUts2ULnHFG9b5mzejlFi9ezPz586c4QkmzmUmuJGlW\nWrduHcuWLZuSugYHB1m6dOmU1CVpbjDJlSTNSosXL2ZwcHDK6pLUX0xyJUmz0vz58219lTRp3ngm\nSZKk1jHJlSRJUuuY5EqSJKl1THIlSZLUOia50hhWr17d6xAkdeE+KmkkfZHkJtknyceTXJFkU5LL\nk6xMctdxjPu2JFfV430nyQNnImbNHp5ApdnNfVTSSPoiyQUWAwFOAJYAK4BXAO/oNlKSNwKvBv4G\neARwC3Bmkl2mNVpJkiTtkL54Tm4p5UzgzMagK5O8hyrRfUOXUV8LvL2U8nWAJMcB1wDHAGdMU7iS\nJEnaQf3SkjuSewLXj/ZlkvsDewJnDQ8rpdwI/Bg4dNqjkyRJ0qT1RUtup7pf7auB13UptidQqFpu\nm66pvxvNPIChoaEdCVGzyMaNG1mzZk2vw5A0CvfR9micO+f1Mg61Q0opvY5h0pKcDLyxS5ECDJRS\nLmuM8z+A7wPfK6W8vEvdhwLnAvctpVzTGP55YGspZfko470A+OxE5kOSJG3jhaWUz/U6CM1tc70l\n9z3AaWOUuWL4jyT3Bb4HnNstwa1dTXWz2kK2bc1dCFzYZbwzgRcCVwJbxpiGJEm60zxgX7a9j0aa\nlDndkjsRdQvu94CfAC8q45jxJFcB7y6lrKo/34Mq4T2ulPIf0xmvJEmSJq8vbjyrW3C/D/ya6mkK\neyRZmGRhR7l1SZ7ZGPR+4C1JnpHkwcBngN8CX5mZyCVJkjQZc727wng9Gdivfv2mHhaqPrs7Ncrt\nDywY/lBKeVeS+cDHqJ7G8EPgaaWUP81E0JIkSZqcvumuIEmSpP7RF90VJEmS1F9MctWXkmxNcnQP\nprs+yWtmerrSbNbG/SLJPvVx5uBexyL1K5NctVKS+yT5SJJfJ9mSZEOSb9bPP4bqH3p8s5cxSnNB\nktPqZG349ft6X3pwr2ObA+wPKPWQSa7a6ovAIcCLqG4ofAbVEzbuDVBKubaUclvPopPmlm9SPSN8\nT+CJwJ+Br/U0ojEkuWuvY6C6wVlSj5jkqnWSLAAeC7yxlHJOKeU3pZSfllJOKaV8vS6zTXeFJI9O\ncmGSzUnOrx8bd8elxiSH1Z+fmOQnSW5Jcl6SAxp17Jfky0muTnJTkguSHDHT8y9Ng1tLKdfVPw4v\nAt4J7JXk3gBJ3pnkF/V+8askb0vSfHIN9T51Qb2PXZfkC6NNLMnLktyQ5An157sn+WySm5P8Jsnf\nJTk7yfsa46xP8pYkn06ykeqpOCR5cJKzkmyqW6E/lmS3xnjb1FMP+1KST3bU/aYkn0hyY32F6ISO\ncR6RZE09fxcAD8WWXKmnTHLVRjfXr2OS7DJW4SS7A18Ffk51YjoReBcjn6D+GVgBLKNqzfpE47u7\nA/8JPAF4CFXr11eT3G/ScyLNMknuTnWF5PJSyh/qwTcCxwEDwGuAl1HtJ8PjPJ3q6srXqfaNw4Hz\nR6n/DcC/AE8qpZxdD14FHAr8T+DIevyHjjD664Gf1dN4e/0IyG8Bf6DaZ58LPAn44IRnHF5H9c+E\nHgJ8GPhIkv3rmHejatm+BFgKrKT6j5ySeqhfnpOrPlJKuT3J8cCpwCuTrAF+APyfUsrFI4zyQmAr\n8Df1M5DXJXkP8O+dVQNvLqWcC1XrFfD1JLuUUv5Ut3Bd1Ch/YpJnA0dTnRSlueoZSW6q/94NuIoq\n4QSglPIvjbL/neS9wPO5M9F7M/C5UsrbGuXWdk4kySlU++PjSynr6mF3p0qg/1cp5fv1sJfUMXQ6\na/g/VNblTgDuRvVfKrcAQ0leDXwtyRtLKdeNdwEA/1lK+Wj99ylJVlD9oL28jjnAy+pjyFCSvXC/\nl3rKlly1UinlS8B9qfrifhM4DFiT5LgRih8AXNTxTz4uGKXqZpK8oX7fA6rWnCTvSXJpfan1JmAx\nsPcOzIo0G3wPOJiqn/vDgTOBb9WJHEmen+Tc+gbPm6iueDS3+4fUdXTz98BLgccOJ7i1/agaZH4y\nPKCUciPwixHqGOz4vBj4eZ3gDjuP6tz3oDHi6dT5A/lq6n2/nk7nMeRHE6xf0hQzyVVr1a2rZ5VS\n3lFKeSzwKeCkHay2ebPacHeG4f3ovcAzgX+g6hN8CNXlyzG7TEiz3C2llPWllCtKKYPACVQtuick\neRRwOlVXhKdTJbTvYNvtfvM4pnEO1X+gfP6OxDmJcbay/Q1iI9201nmjasFzqDSruYOqnwxRnZg7\n/QJ4cMfd2I+YRP2PBj5VSvlqKWUtcC2w7yTqkeaCAuxKtd1fWUp5ZyllTSnlV2y/3V8EjHUT5gXA\n04A3J3l9Y/gVVP3fHz48oL659ADGNgQckmTXxrDHArdzZ0vwdcCiRt13AQ4aR92d0zm44x6AQ0cr\nLGlmmOSqdZLcq76b+oX1ndX7Jnke8L+BL48wyueoWpBOTbI4yZFUN7DAtjefjfQ4oOawy4FnJzkk\nySHAZ0cZR5pr7pZkYf1aTHXj1nyqm60uB/auuyzsl+qfOhzTMf5JwPIkK+t97MH1DWbbKKWcDxwF\nvDXJa+thNwOfBt6T5PAkBwIfp0pUx3p6wWeBLcCnkxxYP63hA8BnGv1xvwc8PclRSR4EfAS458QW\nD5+rY/l4koEkR3HnMURSj5jkqo1uprpz+/+juuHsYqqT7MeAv6vL3HFyLKXcRHUTzSHAhcDbubNb\nQ7Mv30gn1Oaw1wE3UPX5+wrVXd1rupSX5oqnUt3odRXVvrUMeG79iL6vUT394INU+8+jgOYNZpRS\nfgA8j6qP/IXAd2m0zLLt/nge1f749iR/Ww9+HfBfVEn1t4FzgXWMsX+WUjZTPY3hXlQtxWcA3+HO\n4wDAJ6mS6E9TPUv7V2zff7jrvl9KuaWet4Oo9vm3A9sl8ZJmVkrxnCt1SvJCqseDLSil3NrreCTd\nqX402O+A15VSTut1PJJmJx8hJgFJXkTV9+93VDfOvBP4vAmu1HtJHkL1BIMLqLoSvJWqJfUrvYxL\n0uxmkitV9qS6xLqQ6tFgnwfe0tOIJDX9PdXNZn+ielTYY0sp1/c2JEmzmd0VJEmS1DreeCZJkqTW\nMcmVJElS65jkSpIkqXVMciVJktQ6JrmSJElqHZNcSZIktY5JriRJklrHJFeSJEmtY5IrSZKk1jHJ\nlSRJUuuY5EqSJKl1THIlSZLUOia5kiRJah2TXEmSJLWOSa4kSZJaxyRXkiRJrWOSK0mSpNYxyZUk\nSVLr7HCSm+Tfk/whye1JDp7AeOuTvGZHpz9RSY5PcsM01LtPkq0TWQYTqPu0JF/cwToOq9fRPerP\n07IcRpn28Umun4lpzSX1Otk6vE5maJonJlkzU9NrTHfC29t07lPaVufxYZQyM3bM6KV6mzt6guMc\nk+TyJLcled90xTbVenU8aEz7wl5MeyTTFc9M5DpJzp5L2914TWZf7DShJLcz2UryVOA44ChgEXDJ\nCOPMxgNjmUjhcS7o/wb2ZIRlMAVeA7x4B+s4D1hUSrmxMWxCy2EH/B/ggOEPs+3gNhO6HIRmah0M\nezdwxAxPc9hk5nWml8+UmyPb+0jHh5HM+fUxDnsC35zgOB8FzgDuB/zTlEc0BUY5j83I8aDLObQn\n29Nsi0fTZ+cdHP+BwIZSyo+7lAl9sOGUUgpw7TTVfdMU1PFnpji+JHctpdw2jmnfCtzaOXgqY9H4\nlFI2AZt6HccEpNcBTJFp2d7Huw+OZTqOD720I8ullDKh5ZDk7sAewLdLKddMZpp1PVOyLidiDh4P\nNEN6sT1Oh0l3V0hyGvABYO/6V9EVI5Q5DPgksKAuc3uStzaK7JbkE0luTPLrJCd0jH+/JJ9PckPd\nJeLLSfbpEtPw5d+jkvw8yeYkP0py4Bjz8sokv0xya5KhJMc2vltPdYL68mjzWZfb5tJqknsm+WyS\na5NsSvKLJMd3ieG5SS6qy/4+ybeT7Fp/19mCfnaSDyRZleT6JFcneWmS+Uk+WS/Py+uW9s5lM+Ll\nyCT71cv36iQ3JbkgyREdZdYneUuSTyfZCHys23JtjHdHa369DE4EDmlsE8eNMt5pSb6U5E11XDfU\n098pybvqbeI3SV7cMV7X7SbJw+rle12SPyb5fpKHdtSxtV6mX0xyS5LLkjyj8f2412+9rxwGvLYx\nz3s3ijwsyU/q6ZyXZP+O8Z+ZZLDenn+Z5K1JRt13kxye5MdJbq6XwQ+T7FV/t02rYr0sP1CXuzbJ\nO5J8KsmXGmXOTvKvSU6pl+eGJCd2THNFvf3enOS/k3woyW6jxThK3I9IsqaezwuAh9KRHNbb8Y+T\nbElyVZKTm8silTcluaJeLxcmeU7j+4nul+OZ972SfKXebzbW294e9XeT2d7fWse3MclHkuzcKHN2\nkg+m2vevA741jhj2r6d9QMf0ViS5vP778HQcH5K8ONVx+eYkXwDuPULME902J7tPH5TkrNx5fPxY\nc/tq1PvmJL8D1tXDd0nyniS/refjR6nOS6NKo5Uvdx7Xn5Xke6n20Z8leVT9/WHAjVTb6dn1+n18\n/d1zklxSb6vrk7yuYzrbHU8b03teknPq+b2gXocPT3WcuCnJN5Lcu1FX12NaRjmPJVmZbY8Hqdfh\nb+q4L0xyZOP7rstjlOXZ9Rya5Nh6WfwxyeqO9XpkquPXDfV6/1qS/XoYT9Ll+NLFPZJ8rt4Gf5vk\nVR3THOn4Ob+jzGNS7f+3pDrvfzPJglHm8el1/Mvrz+M9zk/o2FJ/v113yrqOszvqHus4+sB6m9+c\nar950jiW69hKKeN+AacBX6z/3h14C/Br4C+Be49QfmeqS+031GX2AObX360HrgNeAewHvBH4M7B/\nY9y1wL8DS4AHAf8/MATsPEp8hwFbqboMPBE4EPgq8Ctgp7rM8cD1jXGeRdXK+HKqlukVwG3AYfX3\n96nrfFEd/3bzWZfbB7gdOLj+/G/AINWJeu86nqePMu6ewJ/qZbV3HfcrGsvqjuVefz4b+CPwZuAB\n9fttwH8CL62HfYiqZWZeY9ncDtxjlOVwMHACMFCPfxJwC3C/Rpn19bpcAdwfuP84t5s7pgXMo7pE\ndlFjm7hbl+1tI9WPqf2pumxspbqU+A91nP9Yr7/7jne7AZ4AvKCu80F12Q3Abo1pb6Xatv+Kavt8\nP9XJ7J6TWL/3oLoc/NHGPIc7t9f/Ah4LLAZ+APywMe7j6nV9LNU2dgTV9vxPo0xrp3odvRPYt56/\nFw2vR6qEa02j/D9S7YdHU3Up+XA9vc7t7Qaqy7APqOu7HTiiUeY19fzsDRwOXAr820jbwChx7wZc\nA3yGahs8Cvgl2+5T9wVurreHA+qYrwXe2jE/a4En1fN/HFVL1eMmut7GM+/1erywXm8PAR4O/AT4\n3iS39xuBz9XL4Gn1Mnl7Rzwb6/W7f/0aLYazG+P9GDipY3o/AVaOcnx4JNXx+PVUx8VXA9ez7TFj\nQtvmDuzT84HfUXUHGKDavn4FfHKEZfepusxAPfxU4IfAo6mOWa+rt4cHdIlxK3B047i+td6mnlov\nizOAK6gaiXau52Mr8Mx6/e4MLKuX35vrcY6jOp4e1+142jG9J1Htv/9Vr6uzgEcBhwCXAR9q1NX1\nmMYo5zG2Px6sqGN6Xl3XO+t18YDxLI9Rlme3ad8I/Ee9zh4DXMW22/uzgWPqZXMw8GXg5x3n3ZmM\np+vxZZTprafaT/43d+5LtzGx4+dDgM3AB4EH1+v4FcC9GseF99V/v6Ce3tMmcZwf77Hlex373hc7\n5nlVR5nxHEcvBr4NHER1Physyxw92rIdz2tihbdPtl4LXDHGOCOe3OoV/6mOYVcDf1P/fSxwacf3\nu1AdKJ40yrSGk4bnNob9RT3Oc0eKBzgX+EhHPZ8HvjbSQa/LfA7vbMMn5K8AHx/ncn1ovTL3Gudy\nPxv4QePzXYCbmssTWFjH84jGshk1yR1luhcDr+pYZ/93whvZ9st8mwPrGNvbFR3DhoDvjzDvf7UD\n281dqHbuozrW+crG5/n1sKdMdP021tn7RthebwcObwx7Wj1sl/rzd4A3doz3QuB3o0znL+rxRzzo\ndi57qhPhio5lcWW37a0e9mPgX7rM73OAa0fbBkYo/zdUCesujWEvZ9sk9x0jrNtXAhsb6/lm4JEd\nZU4FTt+B9TbqvANPpvqBet/G9wP1trJsEtv7dTSS4HoZbOyI56cd440nhtcClzW+P6BetsONCp3H\nh8/SOAbWw1az7X48oW2zMY8T3adPAH5P/YO9sZ/8GfjLRr1X0WgAAfaiSib27Jjed4B/7hLjSEnu\nizuW7e3AAfXnBXWZxzfKnA58q6PeU4CLG5+3O56OMr3n19M7rDHsjXTsCx31jHZMO7qjXOfx4Lcj\nrNMfAx8c7/IYa5l2TPsm6sacxjL6ry71DCeoS2Y6HsZxfBllWuuB/xxhX/p6l3E6j5+fBc7pUv5s\n4H3Aq6h+jD624/vxHucnc2w5jfElud2Oo0+h+jG1sPH9kSOtp4m+ev0IsYs7Pl9N9csKql9t+9dN\n5DcluQn4A3A3ql8CoynA+Xd8KOUG4BdUK2YkA1S/lJvO61J+vD4CLK8vZ5yS5NAuZX9O9Sv9kiRn\nJHlZknuOUf9Fw3+UUrZSLZuLG8OG+4btwTgk2S3VZb1L60saN1G1LO7dUXRwPPVNobUdn69h2/kc\nnvdxbzdJ9khyaqouCH+kOhnsxvbz2pzOJqpf+cPTmcj6HUtzP9hQvw9P5xDgrR3zcyqwMMm8zorq\n7f3TwLeTfDXJa5LsOdJEU12aXkj1y3x4/K2MvI4v6vi8oREjSZ6U5Lv1pbgbqVrP7z1SjKNYDFxU\nSvlTY9iP2LZP7uJ6WNN5wN2T3I+qlWQ+8J2O5fUiqtZ4mNx66zbvi4HflFKuGv6ylDJE1UoymWPI\nz0vVh33Yj6jmb6/GsM71M54Y/g9w/ySPqD+/kCq5uXyUOAaoTkJNnct+Qttmw0T36cVUy2VLY5zz\nqE7UD2oMu7hUfYuHPZjqysZlHTE+nu7nkJF07qOh+7F1oI6x6TyqY1Nzmx7teNqc3vCx/JKOYc39\nb7zHtFEl2Z3qasl4zocTXR6jubI+tjbras7XA+vL/L9K1aVjPdU5ftRj9TTG0+34Mtb21Lnv/IjG\nMh3H8fMhVDlCN8+jSnSfXEo5t1H3RI7zkzm2jNd4jqPNPu2dy2xSdvTGsx3V2am5cGc/4bsDP6Vq\neu+8+eS6aY5rh5VSvpWq3+VRVL+GvpvkQ6WUN4xQdivwlPqE+xTg74B3JHlEKeXXo0xipGU3Uifx\n8f6QeS/V5cbXU10K3Ax8gerXa9Mt46xvqoxnPie63XyGqsXz76ieinEr1Q+jznkddToTWb/j0JxO\nqd+b8/NWYLtHyHWc9JvD/zr5f+2df6ieZRnHP1/BLBBKJQZFdUagpeVKXVM3/8hsleSMJc4FW9IP\nkbSIbZUNq+mGJVvI2aCiLNjmBCMls6hkbf0gxg60SmkHc9ZBS6oRha3ESV798X3e9ew9z/s+z/Oe\nc3Y8764PjHGec/+4nvvHdd/PfV/XdTSKr+9WAJskXRERYwPIViVjR85TwHZxwEPYRGY9Pkm4DLgb\nt2mlnDPA6cX/V+JTvTLPwcD91m+8zQat52BE/FXSHjwvxoCVuL+mQuuxWdB2Tjelu11Ox6e9F+AT\noTJHWpbdb45OhV59WVVf97Ny/U112nQxXe1R1+/fxxvbj+A5fQr+SOqnq2dKnlr9MgiSRqjXn882\nKOoAHusfZvDDqEHW9xeYvNaeWpFuVvToiVDUR/HXdFsOYJuQwxHxh65//aINCNst+QfpDHw1d7BH\n+nFse1NmcVf652n2DnHcDxF/j4idEbEa2zrd0DdzxL6IuA2bLxzF9sInikuxucP3IuJ3+Op4ZIbq\nGnRMNKHJuLkU2BoRPy6+Sp/H12CtaNm/U5kH51S8S6UDZEm230bEnRGxGJ8AfaAizTP4RGhh55ns\nNHRBSxkvBBQR6yJiLCIOAa9uWcY4cL6k8uJ1CcfPqfHiWZklwL8i4k94zj4HvK6ivf7cydB2XjaQ\n+zWSjr2vpHOBV/D/E8s2fb9A0mmlny8BjkTEUwPKUNZju4AVslPOfGyW1a/MRV3Putt+oLE5AOO4\nXV5WerYEX0k/1iffr3G7z6uQsU0EhahPMomqdWUJNhmpK2+Q+protL7rWKEfn6Z+PRxEvqZr6DEk\nnYnX7k0RsTciHqPC+fFEyUND/dKDbke4i/EYAevbOv35CPWh3p7AttlXS9rWeThFPd9Evx3GIWTL\nvKVB2VX1zCs969b/A3EiNrkT+LrtcklndSmqfuzCdlgPSloiaUT2AB6V9KqavJ8v6nsTdkQ4jG3x\nqiO4XXMAAATuSURBVNgMXC/pxuJqZA3eXG7ueod3SJpXY0Zw7GtG0m2Slkl6vRzd4b302GjLXuWf\nlXRhcS35fqygem3MB6VfOKbHgeWSFkhagNt/psI3TeCr0wXFmJjO04Ym4+ZxYJWkN0hahO3nWoXR\nadO/BRPAItkb+KzSlWVVG5ef3Q6slj2ezy1kXiFpYw+5RiTdIeliSa+VtBRv+nvJtg1YX7zL2cAo\nVmBtlMsh4FTZNGK+pFXYlrQN9xZ13i3pjZKuxLcKZb6CFeE2SedIuhrYgG8hiIgjwBbgLkmr5Ygh\nb5V0cyHTIP3Wl4jYjT8idhV1vQ2bi+yNiI7X+gTNx/tLgG+W2mAD7qNBZSgH+n8AO0F+tfjdX7qK\nKo+7rcC7Ja0t9OLN2EauTKuxOQV24dOs7ZLOk/T2Qr4dEdHzVq8wxbgX2CF7348UuvYWSe9pUf8g\nevDLeM24VY6M8EHgJo5fV9rUVydDE502Qf06thn4jKRrJZ0t6UvYLGW0hSxVNKm7m39gs5Ubivl6\nOW7Xbt10QuRpol/6sFjSumIs3ARcg52ZoZn+/CKwUI668Oain2+UPwTKMh7CG93lku4q/WogPd9Q\nv+3BEYJWFbpiA3Yea8NuPIZ3SDpf0mXApu5EcoSVj03K3YcZ3+RGxD7sVX4fPh38VOdXVclL+Z7F\ntlNP4mvzg9je6zRsG9mzSuylO4ptUF4JXNVlq1WW70HslLEWd+ZHsRH7L0rJ1uKrzSfx6UW/ujsc\nBe7A9rY/xddmK3vkewa/6w/wycTtwJqIeLhBPW2e9RvQa7BS+SX+IPgRk9+1Mr8cruZbfcru5v6i\n/L14TFzXIu90jJsP4au9X+EJO8rkGKG96uk8b9O/YOX430Kev2GnmCbv8zDeiL0TXzPvAz6JlXQV\n/8H2Td/BY+lr2Gnk6z3S34k3AtuxLd4R7OFavm6uU4SP4PHzaWwbtxLPwcZExL+Bq7ByPABsLMor\np3kaXxUuBH6DN73fwA5pnTSfK/Legtv6h0WePxZJ2vZbk83+Mjx3fobb7hDHj+k24/0nWNn/HDun\nfBdHOqmTp06GziL9ELZbv6eijPK424914SdwW1+B27VcXtux2Ysmc/pdwJlFPd/GzmMfb1D29fgq\nfwsOK/YAcBHWD03laa1biw3Atdhc6FH8sXJrROysKbdpfd000Wmddewpeq9jW7Fd5xZ8ergUr59P\nTFG+JnUfX6BPvFfgm6JH8QZ3XcO6p12eQqY6/VKZDct+Eb5dWI+dwHYXZdbqz+KDbSmeu/vxOr0M\n669OHZ20v8envtdJ6nxUTUXP99UthR7YWNQxhs06tle0QU+Kvn4fjkazH0cHWV+RdD4tb11Vf3My\nd5BjFu4Bzoj6v9yTTBOSJnDYoJ11aZMXN8UJ8zhwX0R8YbblOZmQ4ym/PCKWz7YsSZIMLyeTnp9t\nx7OZYFj+QtKcQLbP+WducOcmshPWUvyV/lIcw3EEf/UnSZIkc5yTWc/PdgixmWB4jqbnABFxMCLa\nGpknLx5ewFe6Yzho/nk4QHc/h54kSZJk7nDS6vmhMldIkiRJkiRJEhjOk9wkSZIkSZLkJCc3uUmS\nJEmSJMnQkZvcJEmSJEmSZOjITW6SJEmSJEkydOQmN0mSJEmSJBk6cpObJEmSJEmSDB25yU2SJEmS\nJEmGjtzkJkmSJEmSJEPH/wBzvIP89Wm9JgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a34d35278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_f = 2\n",
    "signal = stx[np.where(y == 1), idx_f + 1]\n",
    "background = stx[np.where(y == 0), idx_f + 1]\n",
    "\n",
    "plot = plt.figure()\n",
    "plt.boxplot([signal, background], 0, '')\n",
    "plt.xticks([1, 2], ['Signal', 'Background'])\n",
    "plot.suptitle('Signal and Background distribution of Feature {f}'.format(f = idx_f + 1))\n",
    "\n",
    "textvar = plot.text(0, 0, 'If the plot is similar, it means the signal does not provide more information than the background.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_correlation(stx):\n",
    "    corr = np.ones((stx.shape[1]-1, stx.shape[1]-1))\n",
    "    for feature1 in range(1, stx.shape[1]):\n",
    "        for feature2 in range(1, stx.shape[1]):\n",
    "            corr[feature1-1, feature2-1] = np.corrcoef(stx[:, feature1], stx[:, feature2])[0, 1]\n",
    "            if (corr[feature1-1, feature2-1] >= 0.9 and feature1-1 != feature2-1):\n",
    "                \n",
    "                print(\"Features {f1} and {f2} are highly correlated: {corr}\".format(f1 =feature1-1, f2 = feature2-1, corr = corr[feature1-1, feature2-1]))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features 9 and 21 are highly correlated: 0.9044814595684958\n",
      "Features 9 and 29 are highly correlated: 0.9656283889163997\n",
      "Features 21 and 9 are highly correlated: 0.9044814595684957\n",
      "Features 29 and 9 are highly correlated: 0.9656283889163997\n"
     ]
    }
   ],
   "source": [
    "corr = calculate_correlation(stx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_del = np.array([22, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_correlation_with_y(stx, y, threshold):\n",
    "    corr = np.ones(stx.shape[1]-1)\n",
    "    for feature in range(1, stx.shape[1]):\n",
    "        corr[feature-1] = np.corrcoef(y, stx[:, feature])[0, 1] \n",
    "        if (abs(corr[feature-1]) <= threshold):\n",
    "            print(\"feature {f} is not correlated with y: {corr}\".format(f = feature-1, corr= corr[feature-1]))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 14 is not correlated with y: -0.0009432510582117535\n",
      "feature 15 is not correlated with y: -0.00440253868638843\n",
      "feature 17 is not correlated with y: 0.001516235377059733\n",
      "feature 18 is not correlated with y: 0.00412544741152486\n",
      "feature 24 is not correlated with y: 7.15909820593841e-05\n",
      "feature 25 is not correlated with y: 0.0009043288374294407\n",
      "feature 27 is not correlated with y: 0.0005721318815439868\n",
      "feature 28 is not correlated with y: -0.003524581655021693\n"
     ]
    }
   ],
   "source": [
    "corr = calculate_correlation_with_y(stx, y, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_del = np.append(idx_to_del, [ 15, 16, 18, 19, 25, 26, 28, 29])\n",
    "#idx_to_del = np.append(idx_to_del, [ 15, 16, 18, 19, 21, 25, 26, 28, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 29 28 26 25 22 19 18 16 15]\n"
     ]
    }
   ],
   "source": [
    "idx_to_del = np.sort(idx_to_del)\n",
    "idx_to_del = idx_to_del[::-1]\n",
    "print(idx_to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_features(stx):\n",
    "    return np.delete(stx, idx_to_del, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0263822 , -0.35142796, -0.01405527,  0.19252633,  0.20347244,\n",
       "        0.21249463, -0.18361342,  0.01224548, -0.01528743,  0.15323593,\n",
       "       -0.1953979 ,  0.27175188,  0.17514537,  0.23523798, -0.03194759,\n",
       "        0.02246575,  0.00747534,  0.13354912,  0.11545223,  0.02287271])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tx = delete_features(np.copy(stx))\n",
    "calculate_correlation_with_y(clean_tx, y, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a polynomial basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    dim = degree+1\n",
    "    N = x.shape[0]\n",
    "    phi = np.ones((N, x.shape[1]))\n",
    "    for j in range(1, dim):\n",
    "        phi = np.concatenate((phi, np.power(x,j)), axis =1)\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 63)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 2\n",
    "poly_tx = build_poly(clean_tx, degree)\n",
    "poly_tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def divide_training_data(y, x, ratio ):\n",
    "    \"\"\"Divide a dataset into 2 disjoint parts. We will use this on the training data set \n",
    "    so that we can train on one and test on the other to check the accuracy of our prediction\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(np.arange(len(y)), int( len(y)*ratio ), replace=False)\n",
    "    \n",
    "    # training data \n",
    "    x_train = x[indices]\n",
    "    y_train = y[indices]\n",
    "    \n",
    "    # test data \n",
    "    x_test = x[~indices]\n",
    "    y_test = y[~indices]\n",
    "    \n",
    "\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction( y, tX, gamma, max_iters, lambda_, initial_w  ):\n",
    "    \"\"\"Train on the train part of the data and test on the test part to validate the model\"\"\"\n",
    "    x_train, x_test, y_train, y_test = divide_training_data(y, tX, 0.7 )\n",
    "    \n",
    "    loss = 0\n",
    "    w = []\n",
    "    loss, w = reg_logistic_regression( y_train, x_train, lambda_, gamma, max_iters )\n",
    "    \n",
    "    y_pred = predict_labels(w, x_test)    \n",
    "    y_pred = set_y(y_pred)\n",
    "    \n",
    "    # accuracy of the prediction\n",
    "    N = y_test.shape\n",
    "    print(N, y_pred.shape)\n",
    "    pred = np.sum(y_pred == y_test)/N[0]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.26246845e-02,   1.12555408e-03,  -1.49630998e-02,\n",
       "         -5.27639545e-04,   7.02221903e-03,   8.08978174e-03,\n",
       "          8.11769979e-03,  -7.14295078e-03,   1.59108512e-03,\n",
       "         -1.30569868e-03,   5.17468251e-03,  -8.33403032e-03,\n",
       "          1.10322802e-02,   7.16516296e-03,   9.56867131e-03,\n",
       "         -5.00683515e-05,  -2.02282621e-04,  -1.53553951e-03,\n",
       "          4.60885699e-05,   1.85119866e-04,   1.08180533e-04,\n",
       "          3.07448491e-04,   4.43231567e-03,   4.54581600e-03,\n",
       "          3.71286308e-03,   2.90482476e-06,   3.16264988e-05,\n",
       "          4.23474030e-05,   3.18010251e-05,  -1.40331564e-04,\n",
       "          4.26636111e-03]), 0.15160026197005938)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_w = np.zeros(stx.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.001\n",
    "\n",
    "least_squares_GD(y, stx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.42652972e-01,  -6.82429969e-03,  -1.20053703e-01,\n",
       "         -7.60258575e-02,   2.18634038e-02,   1.75429763e-02,\n",
       "          4.13991244e-02,   5.07979004e-04,   1.05803005e-01,\n",
       "         -1.41598873e-02,   1.71970141e-02,  -5.77982349e-02,\n",
       "          6.24719504e-02,   3.63223883e-02,   8.38913851e-02,\n",
       "          8.05147936e-06,  -6.45499390e-04,   8.15212555e-02,\n",
       "         -3.26788905e-04,   1.22435912e-03,   3.35698968e-02,\n",
       "          6.78002148e-05,  -1.80964935e-02,   4.56517065e-03,\n",
       "         -2.20299761e-02,   9.16153743e-06,   6.01597954e-04,\n",
       "         -1.35431395e-02,   1.08769143e-03,  -1.31712823e-03,\n",
       "         -1.72333432e-02]), 0.085540862775766183)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.1\n",
    "least_squares_SGD(y, stx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.42668000e-01,   6.11361314e-03,  -1.26533292e-01,\n",
       "         -1.31728099e-01,   6.46217226e-03,   9.64026088e-03,\n",
       "          5.20573141e-02,   3.57195511e-03,   1.40111528e-01,\n",
       "         -1.38806755e-02,  -1.60323202e+02,  -9.38377506e-02,\n",
       "          6.00765800e-02,   3.72963099e-02,   3.11465307e+01,\n",
       "         -4.00142227e-04,  -4.05770496e-04,   3.07170376e+01,\n",
       "         -3.26073105e-04,   1.27894398e-03,   5.01947429e-02,\n",
       "          4.71663263e-04,  -2.39219337e-02,   2.73366768e-02,\n",
       "         -1.86624775e-02,   2.92313230e-04,   1.24560590e-04,\n",
       "         -9.10599047e-03,   7.58088080e-04,  -8.07604911e-04,\n",
       "          1.35788484e+02]), 0.084989533074598111)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_squares(y, stx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.42667863e-01,   6.11297319e-03,  -1.26538540e-01,\n",
       "         -1.31725593e-01,   6.46088980e-03,   9.63885056e-03,\n",
       "          5.20609183e-02,   3.57572226e-03,   1.40110603e-01,\n",
       "         -1.38823980e-02,   9.52716103e-03,  -9.38353284e-02,\n",
       "          6.00747147e-02,   3.72989396e-02,   9.03488696e-02,\n",
       "         -4.00598225e-04,  -4.05611588e-04,   1.41908324e-01,\n",
       "         -3.25120523e-04,   1.27773001e-03,   5.01978869e-02,\n",
       "          4.72869042e-04,  -2.39169434e-02,   2.73366514e-02,\n",
       "         -1.86663923e-02,   2.92969358e-04,   1.24633015e-04,\n",
       "         -9.10739964e-03,   7.57952288e-04,  -8.05691791e-04,\n",
       "         -3.07741702e-02]), 0.084989820561928331)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "ridge_regression(y, stx, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using gradient or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=[ 173286.79513999]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ -7.99164213e-01,  -3.82177695e-02,  -6.47271596e-01,\n",
       "         -2.34822096e-01,   1.93134902e-01,   8.80119232e-02,\n",
       "          2.13535323e-01,  -2.44198634e-02,   4.51242010e-01,\n",
       "         -9.75654639e-02,   6.61573396e-02,  -2.70515076e-01,\n",
       "          2.99966260e-01,   1.78630879e-01,   3.91223147e-01,\n",
       "         -3.85215356e-03,  -5.28744162e-03,   2.44837602e-01,\n",
       "         -1.89458727e-03,   6.87560818e-03,   4.90217893e-02,\n",
       "          3.12141991e-03,  -4.31313227e-02,  -1.37513690e-02,\n",
       "         -4.04791233e-02,   1.36205377e-04,   1.97982467e-03,\n",
       "         -8.88506504e-02,   4.35008009e-03,  -2.93226649e-03,\n",
       "         -6.64753884e-02]), array([ 127999.19292002]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iters = 100\n",
    "gamma = 0.000001\n",
    "logistic_regression(y, stx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized  logistic  regression  using  gradient  descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=[ 173286.79513999]\n",
      "Current iteration=100, the loss=[ 150060.96001291]\n",
      "Current iteration=200, the loss=[ 142037.96232546]\n",
      "Current iteration=300, the loss=[ 137899.78894857]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8fff336c4ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/kirtan/Academics/EPFL/sem1/ML/PCML-Project1/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;31m# log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kirtan/Academics/EPFL/sem1/ML/PCML-Project1/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlearning_by_gradient_descent\u001b[0;34m(y, tx, w, gamma, lambda_)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kirtan/Academics/EPFL/sem1/ML/PCML-Project1/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mcalculate_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlearning_by_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gamma = 5e-8\n",
    "max_iters = 1000\n",
    "lambda_ = 0.07\n",
    "reg_logistic_regression(y, stx, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../Data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_test = delete_outliers(tX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stx_test, mean_stx_test, std_x_test = standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test = delete_features(stx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 84)\n"
     ]
    }
   ],
   "source": [
    "poly_test = build_poly(clean_test, degree)\n",
    "print(poly_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../Data/Data_submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, poly_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
